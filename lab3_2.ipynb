{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmitr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dmitr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Створення генератора зображень\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 988 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 988 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Завантаження даних\n",
    "training_set = train_datagen.flow_from_directory('pictures', target_size = (64, 64), batch_size = 32, class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('pictures', target_size = (64, 64), batch_size = 32, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dmitr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dmitr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Створення моделі\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dmitr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Компіляція моделі\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmitr\\AppData\\Local\\Temp\\ipykernel_21292\\675993463.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(training_set, steps_per_epoch = 30, epochs = 25, validation_data = test_set, validation_steps = 500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 1.4318 - accuracy: 0.4153WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n",
      "30/30 [==============================] - 7s 223ms/step - loss: 1.4318 - accuracy: 0.4153 - val_loss: 1.3115 - val_accuracy: 0.4534\n",
      "Epoch 2/25\n",
      "30/30 [==============================] - 4s 141ms/step - loss: 1.2617 - accuracy: 0.5230\n",
      "Epoch 3/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 1.1894 - accuracy: 0.5439\n",
      "Epoch 4/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 1.0898 - accuracy: 0.5868\n",
      "Epoch 5/25\n",
      "30/30 [==============================] - 4s 132ms/step - loss: 1.0295 - accuracy: 0.5994\n",
      "Epoch 6/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.9692 - accuracy: 0.6496\n",
      "Epoch 7/25\n",
      "30/30 [==============================] - 4s 141ms/step - loss: 0.9590 - accuracy: 0.6255\n",
      "Epoch 8/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.8880 - accuracy: 0.6527\n",
      "Epoch 9/25\n",
      "30/30 [==============================] - 4s 132ms/step - loss: 0.8129 - accuracy: 0.7092\n",
      "Epoch 10/25\n",
      "30/30 [==============================] - 4s 132ms/step - loss: 0.7882 - accuracy: 0.7144\n",
      "Epoch 11/25\n",
      "30/30 [==============================] - 4s 132ms/step - loss: 0.7590 - accuracy: 0.7218\n",
      "Epoch 12/25\n",
      "30/30 [==============================] - 4s 135ms/step - loss: 0.7217 - accuracy: 0.7448\n",
      "Epoch 13/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.7793 - accuracy: 0.7249\n",
      "Epoch 14/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.6735 - accuracy: 0.7678\n",
      "Epoch 15/25\n",
      "30/30 [==============================] - 4s 133ms/step - loss: 0.7185 - accuracy: 0.7364\n",
      "Epoch 16/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.6577 - accuracy: 0.7709\n",
      "Epoch 17/25\n",
      "30/30 [==============================] - 4s 133ms/step - loss: 0.6874 - accuracy: 0.7500\n",
      "Epoch 18/25\n",
      "30/30 [==============================] - 4s 136ms/step - loss: 0.6285 - accuracy: 0.7803\n",
      "Epoch 19/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.5709 - accuracy: 0.7950\n",
      "Epoch 20/25\n",
      "30/30 [==============================] - 4s 138ms/step - loss: 0.5445 - accuracy: 0.8054\n",
      "Epoch 21/25\n",
      "30/30 [==============================] - 4s 134ms/step - loss: 0.5160 - accuracy: 0.8180\n",
      "Epoch 22/25\n",
      "30/30 [==============================] - 4s 137ms/step - loss: 0.4568 - accuracy: 0.8400\n",
      "Epoch 23/25\n",
      "30/30 [==============================] - 4s 132ms/step - loss: 0.4615 - accuracy: 0.8274\n",
      "Epoch 24/25\n",
      "30/30 [==============================] - 4s 135ms/step - loss: 0.4332 - accuracy: 0.8515\n",
      "Epoch 25/25\n",
      "30/30 [==============================] - 4s 132ms/step - loss: 0.4360 - accuracy: 0.8479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2dae3f64790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Навчання моделі\n",
    "model.fit_generator(training_set, steps_per_epoch = 30, epochs = 25, validation_data = test_set, validation_steps = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 988 images belonging to 5 classes.\n",
      "Found 988 images belonging to 5 classes.\n",
      "Epoch 1/30\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.8946 - accuracy: 0.2286WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
      "25/25 [==============================] - 7s 241ms/step - loss: 1.8946 - accuracy: 0.2286 - val_loss: 1.5583 - val_accuracy: 0.3249\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 1.5608 - accuracy: 0.3237\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 3s 134ms/step - loss: 1.5252 - accuracy: 0.3593\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 3s 133ms/step - loss: 1.4312 - accuracy: 0.4095\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 3s 132ms/step - loss: 1.3924 - accuracy: 0.4296\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 3s 133ms/step - loss: 1.3574 - accuracy: 0.4497\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 3s 132ms/step - loss: 1.3599 - accuracy: 0.4259\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 3s 133ms/step - loss: 1.3030 - accuracy: 0.4749\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 1.3107 - accuracy: 0.4799\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 3s 134ms/step - loss: 1.2138 - accuracy: 0.4937\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 1.2010 - accuracy: 0.5075\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 1.1334 - accuracy: 0.5603\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 1.1795 - accuracy: 0.5214\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 3s 133ms/step - loss: 1.1527 - accuracy: 0.5440\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 3s 134ms/step - loss: 1.1084 - accuracy: 0.5350\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 3s 134ms/step - loss: 1.1285 - accuracy: 0.5562\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 1.0949 - accuracy: 0.5729\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 3s 134ms/step - loss: 1.0200 - accuracy: 0.6143\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 1.0696 - accuracy: 0.5962\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 1.0462 - accuracy: 0.6244\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 1.0345 - accuracy: 0.5917\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 4s 139ms/step - loss: 1.0283 - accuracy: 0.5842\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 4s 139ms/step - loss: 0.9795 - accuracy: 0.6143\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 3s 134ms/step - loss: 0.9905 - accuracy: 0.6112\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 0.9273 - accuracy: 0.6420\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 0.9266 - accuracy: 0.6432\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 0.9179 - accuracy: 0.6432\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 0.9288 - accuracy: 0.6357\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 0.9253 - accuracy: 0.6438\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 0.9147 - accuracy: 0.6382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2daf1376340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Створюємо генератори для тренування та тестування зображень\n",
    "# Вони автоматично масштабують зображення, виконують аугментацію даних (для тренувального набору) та готують їх до подачі в модель\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Завантажуємо тренувальні та тестові дані\n",
    "training_set = train_datagen.flow_from_directory('pictures', target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "test_set = test_datagen.flow_from_directory('pictures', target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Створюємо модель\n",
    "model = Sequential()\n",
    "\n",
    "# Додаємо шари до моделі\n",
    "# Перший шар - це згортковий шар з 32 фільтрами, ядром 3x3 та функцією активації ReLU\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# Додаємо шар максимального пулінгу з розміром вікна 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Додаємо шар Dropout для запобігання перенавчання\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Додаємо шар Flatten для перетворення вхідних даних в одновимірний масив\n",
    "model.add(Flatten())\n",
    "\n",
    "# Додаємо повнозв'язний шар з 128 нейронами та функцією активації ReLU\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Додаємо ще один шар Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Додаємо вихідний шар з 5 нейронами (один для кожного класу) та функцією активації softmax\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "# Компілюємо модель\n",
    "# Використовуємо оптимізатор Adam, функцію втрат категоріальної кросс-ентропії та метрику точності\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчаємо модель\n",
    "model.fit(training_set, steps_per_epoch=25, epochs=30, validation_data=test_set, validation_steps=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
